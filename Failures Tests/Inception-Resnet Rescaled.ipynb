{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comfortable-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11436188741616876499\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 18221557875297050748\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7046801664\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9168539278456946877\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14942742832874168821\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import ESC\n",
    "\n",
    "# Use GPU\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-paraguay",
   "metadata": {},
   "source": [
    "## Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "scientific-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved data\n",
    "def Load_Augmented(name='', path='Augmented_Data/'):\n",
    "    '''\n",
    "        Input:\n",
    "            name:      name of the file\n",
    "            path:      path of the file\n",
    "        \n",
    "        Output:\n",
    "            dataset:   loaded dataset with data and labels\n",
    "    '''\n",
    "    hf = h5py.File(path + name + '.h5', 'r')\n",
    "    data =  np.array(hf.get('data'))\n",
    "    labels = np.array(hf.get('label'))\n",
    "    hf.close()\n",
    "    \n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    label = np.asarray(labels, dtype=np.float32)\n",
    "    '''\n",
    "    dataset = []\n",
    "    for i in range(len(data)):\n",
    "        dataset.append([data[i], labels[i]])\n",
    "    \n",
    "    dataset = np.asarray(dataset, dtype=object)\n",
    "    '''\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def Preprocessing(raw_audio, labels, bands=60, frames=41):\n",
    "    '''\n",
    "        Input:\n",
    "            raw_audio:     list that contains the raw/augmented data\n",
    "            labels:        list that contains the category information\n",
    "            bands:         number of mel band to use\n",
    "            frames:        number of frames to use\n",
    "        \n",
    "        Output:\n",
    "            features:      numpy array that contains processed audio data with log-melspec and delta\n",
    "            new_labels:    new labels for each augmented segment\n",
    "    '''    \n",
    "    \n",
    "    new_labels = []\n",
    "    augmented_spec = []\n",
    "    \n",
    "    # Normalize the raw data\n",
    "    norm_factor = np.percentile(raw_audio, 99) - np.percentile(raw_audio, 5)\n",
    "    raw_audio = raw_audio / norm_factor\n",
    "    \n",
    "    # Loop over each file audio\n",
    "    for num, audio in enumerate(tqdm(raw_audio)):\n",
    "    \n",
    "        # Convert audio to melspectogram\n",
    "        '''\n",
    "            With default n_fft=2048 we have the filter size of 2048/2+1=1025 [Nyquist Frequency]\n",
    "        '''\n",
    "        melspec = librosa.feature.melspectrogram(audio, n_mels=bands, hop_length=512)\n",
    "        \n",
    "        # Convert melspec to log melspec\n",
    "        logspec = librosa.core.amplitude_to_db(melspec)\n",
    "        \n",
    "        counter = 0\n",
    "        # Spectrogram splitting with 50% overlap and adapt cv-fold and labels info\n",
    "        for idx in range(0, len(logspec[0]) - frames, int(frames/2)):\n",
    "            augmented_spec.append(logspec[:, idx:idx+frames])\n",
    "            new_labels.append(labels[num])\n",
    "            counter = counter +1\n",
    "            \n",
    "    # Reshape the outputs\n",
    "    log_specgrams = np.asarray(augmented_spec).reshape(len(augmented_spec), bands, frames, 1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    new_labels = np.asarray(new_labels)\n",
    "    \n",
    "    # Fill the delta features\n",
    "    for i in range(len(log_specgrams)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    features = features.astype(np.float64)\n",
    "    labels = labels.astype(np.float32)\n",
    "    return features, new_labels\n",
    "\n",
    "\n",
    "\n",
    "def CreateTrainingSet(f1, f2, f3, lf1, lf2, lf3, batch_size=32):\n",
    "    \n",
    "    # Create training set\n",
    "    merged_training_data = np.concatenate((f1, f2, f3))\n",
    "    merged_training_label = np.concatenate((lf1, lf2, lf3))\n",
    "\n",
    "    # Create and cache training\n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((merged_training_data, merged_training_label))\n",
    "    training_dataset = training_dataset.batch(batch_size=batch_size)\n",
    "    training_dataset = training_dataset.cache(\"training_cache\")\n",
    "    training_dataset = training_dataset.prefetch(buffer_size=1)\n",
    "    \n",
    "    return training_dataset\n",
    "\n",
    "\n",
    "\n",
    "def CreateValidationSet(f1, lf1, batch_size=32):\n",
    "\n",
    "    # Create and cache training\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((f1, lf1))\n",
    "    validation_dataset = validation_dataset.cache(\"validation_cache\")\n",
    "    validation_dataset = validation_dataset.batch(batch_size=batch_size)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size=1)\n",
    "    \n",
    "    return validation_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-civilization",
   "metadata": {},
   "source": [
    "## Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackBoneNet(input_shape):\n",
    "    \n",
    "    X_input = tf.keras.Input(input_shape)\n",
    "    \n",
    "    # First branch with basic 3x3 kernel\n",
    "    model = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=2, padding='same', name='b1_conv0')(X_input)\n",
    "    model = tf.keras.layers.BatchNormalization(axis=3)(model)\n",
    "    model = tf.keras.layers.Activation('relu')(model)\n",
    "    \n",
    "    # Second branch with two stacked 3x3 kernel should equal to a single 9x9 from the original input\n",
    "    branch_2 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', name='b2_conv0')(X_input)\n",
    "    branch_2 = tf.keras.layers.BatchNormalization(axis=3)(branch_2)\n",
    "    branch_2 = tf.keras.layers.Activation('relu')(branch_2)\n",
    "    branch_2 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(2, 2), padding='same', name='b2_conv1')(branch_2)\n",
    "    branch_2 = tf.keras.layers.BatchNormalization(axis=3)(branch_2)\n",
    "    branch_2 = tf.keras.layers.Activation('relu')(branch_2)\n",
    "\n",
    "    \n",
    "    # Third branch with stacked dilated kernel\n",
    "    branch_3 = tf.keras.layers.Conv2D(32, kernel_size=(5, 5), dilation_rate=(2, 2), padding='same', name='b3_conv0')(X_input)\n",
    "    branch_3 = tf.keras.layers.BatchNormalization(axis=3)(branch_3)\n",
    "    branch_3 = tf.keras.layers.Activation('relu')(branch_3)\n",
    "\n",
    "    # Fifth branch with stacked dilated kernel\n",
    "    branch_4 = tf.keras.layers.Conv2D(32, kernel_size=(5, 5), dilation_rate=(4, 4), padding='same', name='b5_conv0')(X_input)\n",
    "    branch_4 = tf.keras.layers.BatchNormalization(axis=3)(branch_4)\n",
    "    branch_4 = tf.keras.layers.Activation('relu')(branch_4)\n",
    "    \n",
    "    sdc = tf.concat(values=[branch_3, branch_4], axis=3, name='stacked_dilated_conv')\n",
    "    sdc = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=2, padding='same', name='sdc_conv')(sdc)\n",
    "    \n",
    "    \n",
    "    # Contanetare all the parallel branches\n",
    "    X = tf.concat(values=[model, branch_2, sdc], axis=3, name='test')\n",
    "    \n",
    "\n",
    "    ##### MAIN PATH ##### \n",
    "    # First component of main path (3 lines)\n",
    "    main_path = tf.keras.layers.Conv2D(128, kernel_size=1, strides=2, padding='valid', kernel_initializer='glorot_uniform', name='main_path_' + '1st')(X)\n",
    "    main_path = tf.keras.layers.BatchNormalization(axis=3)(main_path)\n",
    "    main_path = tf.keras.layers.Activation('relu')(main_path)\n",
    "    \n",
    "    # Second component of main path (3 lines)\n",
    "    main_path = tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_uniform', name='main_path_' + '2nd')(main_path)\n",
    "    main_path = tf.keras.layers.BatchNormalization(axis=3)(main_path)\n",
    "    main_path = tf.keras.layers.Activation('relu')(main_path)\n",
    "\n",
    "    # Third component of main path (2 lines)\n",
    "    main_path = tf.keras.layers.Conv2D(256, kernel_size=1, strides=1, padding='valid', kernel_initializer='glorot_uniform', name='main_path_' + '3rd')(main_path)\n",
    "    main_path = tf.keras.layers.BatchNormalization(axis=3)(main_path)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (2 lines)\n",
    "    X_shortcut = tf.keras.layers.Conv2D(256, kernel_size=1, strides=2, padding='valid', kernel_initializer='glorot_uniform', name='shortcut')(X)\n",
    "    X_shortcut = tf.keras.layers.BatchNormalization(axis=3)(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X_final = tf.keras.layers.Add()([X_shortcut, main_path])\n",
    "    X_final = tf.keras.layers.BatchNormalization(axis=3)(X_final)\n",
    "    X_final = tf.keras.layers.Activation('relu')(X_final)\n",
    "    \n",
    "    # Flatten and fully connect the features\n",
    "    model = tf.keras.layers.Flatten()(X_final)\n",
    "    model = tf.keras.layers.Dense(5000, activation='relu', name='fc0')(model)\n",
    "    model = tf.keras.layers.Dropout(0.5)(model)\n",
    "    model = tf.keras.layers.Dense(1000, activation='relu', name='fc1')(model)\n",
    "    model = tf.keras.layers.Dropout(0.5)(model)\n",
    "    \n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs=X_input, outputs=model, name='DevNet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def ESC50Classifier(input_shape=1000):\n",
    "    \n",
    "    X_input = tf.keras.Input(input_shape)\n",
    "    \n",
    "    # Feature reduction\n",
    "    model = tf.keras.layers.Dense(500, activation='relu', name='c_fc1')(X_input)\n",
    "    model = tf.keras.layers.Dropout(0.5)(model)\n",
    "    \n",
    "    # Output classifier layer\n",
    "    model = tf.keras.layers.Dense(50, activation='softmax', name='out')(model)\n",
    "    \n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs=X_input, outputs=model, name='ESC50_Classifier')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def Docking(back_bone, classifier):\n",
    "    \n",
    "    model = tf.keras.Model(inputs=back_bone.input, outputs=classifier(back_bone.output).output, name='Merged')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-import",
   "metadata": {},
   "source": [
    "## Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geographic-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "BackboneNet = BackBoneNet([60, 41, 2])\n",
    "Classifier50 = ESC50Classifier([1000])\n",
    "\n",
    "MFNet = Docking(BackboneNet, Classifier50)\n",
    "opt = tf.keras.optimizers.Adam(lr=0.000001)\n",
    "loss_f = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "MFNet.compile(optimizer=opt, loss=loss_f, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-birth",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "round-sodium",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:20<00:00, 24.93it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 659948.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds size: 400 - 400 - 400 - 400 - 400\n",
      "Folds sample shape:  2\n",
      "Folds sample data shape:  (110250,)\n",
      "Folds sample label type:  (50,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:02<00:00, 150.32it/s]\n",
      "100%|██████████| 400/400 [00:02<00:00, 151.92it/s]\n",
      "100%|██████████| 400/400 [00:02<00:00, 147.06it/s]\n",
      "100%|██████████| 400/400 [00:02<00:00, 150.55it/s]\n"
     ]
    }
   ],
   "source": [
    "PATH = 'audio'\n",
    "raw_files, cvs, labels = ESC.Load_RAW(PATH)\n",
    "\n",
    "# Split the different folds\n",
    "f1, f2, f3, f4, f5 = ESC.Split_Folds(raw_files, cvs, labels, verbose=True)\n",
    "\n",
    "# Split data label\n",
    "f1d, f1l = ESC.Split_Data_Label(f1)\n",
    "f2d, f2l = ESC.Split_Data_Label(f2)\n",
    "f3d, f3l = ESC.Split_Data_Label(f3)\n",
    "f4d, f4l = ESC.Split_Data_Label(f4)\n",
    "\n",
    "# Compute log-melspec and deltas\n",
    "f1p, lf1p = ESC.Preprocessing(f1d, f1l)\n",
    "f2p, lf2p = ESC.Preprocessing(f2d, f2l)\n",
    "f3p, lf3p = ESC.Preprocessing(f3d, f3l)\n",
    "f4p, lf4p = ESC.Preprocessing(f4d, f4l)\n",
    "\n",
    "f1p = np.interp(f1p, (f1p.min(), f1p.max()), (0, +1))\n",
    "f2p = np.interp(f2p, (f2p.min(), f2p.max()), (0, +1))\n",
    "f3p = np.interp(f3p, (f3p.min(), f3p.max()), (0, +1))\n",
    "f4p = np.interp(f4p, (f4p.min(), f4p.max()), (0, +1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "about-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and validation set\n",
    "training_dataset = ESC.CreateTrainingSet(f1p, f2p, f3p, lf1p, lf2p, lf3p, batch_size=64)\n",
    "validation_dataset = ESC.CreateValidationSet(f4p, lf4p, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "french-second",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Merged/b1_conv0/Conv2D (defined at <ipython-input-7-c636a6ef7a56>:24) ]] [Op:__inference_train_function_3678]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c636a6ef7a56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# train on batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mstep_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMFNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# save loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1693\u001b[0m                                                     class_weight)\n\u001b[0;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Merged/b1_conv0/Conv2D (defined at <ipython-input-7-c636a6ef7a56>:24) ]] [Op:__inference_train_function_3678]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 30\n",
    "\n",
    "epoch_loss= []\n",
    "epoch_acc = []\n",
    "\n",
    "epoch_vl = []\n",
    "epoch_va = []\n",
    "\n",
    "# Loop over the epochs\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    \n",
    "    step_loss = []\n",
    "    step_acc = []\n",
    "    \n",
    "    step_vl = []\n",
    "    step_va = []\n",
    "    \n",
    "    start = time.time()\n",
    "    # train over mini-batches\n",
    "    for x_batch, y_batch in training_dataset:\n",
    "        \n",
    "        # train on batch\n",
    "        step_stats = MFNet.train_on_batch(x_batch, y_batch)\n",
    "        \n",
    "        # save loss and accuracy\n",
    "        step_loss.append(step_stats[0])\n",
    "        step_acc.append(step_stats[1])\n",
    "        \n",
    "    # compute validation stats\n",
    "    for x_batch, y_batch in validation_dataset:\n",
    "        \n",
    "        # compute validation stats\n",
    "        val_stats = MFNet.test_on_batch(x_batch, y_batch)\n",
    "        \n",
    "        # save loss and accuracy\n",
    "        step_vl.append(val_stats[0])\n",
    "        step_va.append(val_stats[1])\n",
    "    end = time.time()\n",
    "        \n",
    "    # Save the mean loss and accuracy of the entire epoch\n",
    "    epoch_loss.append(np.mean(step_loss))\n",
    "    epoch_acc.append(np.mean(step_acc))\n",
    "    epoch_vl.append(np.mean(step_vl))\n",
    "    epoch_va.append(np.mean(step_va))\n",
    "    \n",
    "    # Print epoch training stats\n",
    "    print(\"Epoch %2d: \\t t-loss: %3.6f \\t t-acc: %.6f \\t v-loss: %3.6f \\t v-acc: %.6f \\t time: %3.3f\" % (epoch + 1, epoch_loss[-1], epoch_acc[-1], epoch_vl[-1], epoch_va[-1], (end - start)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epoch_loss, label='T-loss')\n",
    "plt.plot(epoch_vl, label='V-loss')\n",
    "plt.title('Loss plot')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epoch_acc, label='T-acc')\n",
    "plt.plot(epoch_va, label='V-acc')\n",
    "plt.title('Accuracy plot')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-extreme",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
