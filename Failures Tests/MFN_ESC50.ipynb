{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "directed-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ESC3\n",
    "import multiprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session, clear_session, get_session\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-study",
   "metadata": {},
   "source": [
    "## Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "massive-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_train_loss = []\n",
    "fold_train_accuracy = []\n",
    "fold_valid_loss = []\n",
    "fold_valid_accuracy = []\n",
    "fold_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quick-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    \n",
    "    # Get and close session\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "    \n",
    "    # Garbage collector call\n",
    "    gc.collect()\n",
    "    \n",
    "    # Init new session\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advance-evening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#############################################################\n",
      "######################## FOLD-1 #############################\n",
      "#############################################################\n",
      "Epoch  1: \t t-loss: 37.714409 \t t-acc: 0.093750 \t v-loss: 3.984796 \t v-acc: 0.025789 \t time: 4.901\n",
      "Epoch  2: \t t-loss: 3.887333 \t t-acc: 0.221875 \t v-loss: 4.313457 \t v-acc: 0.021086 \t time: 3.111\n",
      "Epoch  3: \t t-loss: 3.304750 \t t-acc: 0.096875 \t v-loss: 4.139375 \t v-acc: 0.021845 \t time: 3.100\n",
      "Epoch  4: \t t-loss: 2.360854 \t t-acc: 0.262500 \t v-loss: 4.317555 \t v-acc: 0.021845 \t time: 3.103\n",
      "Epoch  5: \t t-loss: 2.106009 \t t-acc: 0.259375 \t v-loss: 4.425918 \t v-acc: 0.021845 \t time: 3.101\n",
      "Epoch  6: \t t-loss: 1.975324 \t t-acc: 0.237500 \t v-loss: 5.013802 \t v-acc: 0.021845 \t time: 3.100\n",
      "Epoch  7: \t t-loss: 2.058517 \t t-acc: 0.162500 \t v-loss: 4.794616 \t v-acc: 0.021845 \t time: 3.111\n",
      "Epoch  8: \t t-loss: 1.998615 \t t-acc: 0.262500 \t v-loss: 4.804891 \t v-acc: 0.021845 \t time: 3.110\n",
      "Epoch  9: \t t-loss: 1.974377 \t t-acc: 0.262500 \t v-loss: 5.067041 \t v-acc: 0.021845 \t time: 3.102\n",
      "Epoch 10: \t t-loss: 1.990379 \t t-acc: 0.262500 \t v-loss: 4.994855 \t v-acc: 0.021845 \t time: 3.104\n",
      "Epoch 11: \t t-loss: 1.945217 \t t-acc: 0.262500 \t v-loss: 5.227107 \t v-acc: 0.021845 \t time: 3.111\n",
      "Epoch 12: \t t-loss: 1.961461 \t t-acc: 0.265625 \t v-loss: 5.243683 \t v-acc: 0.021845 \t time: 3.110\n",
      "Epoch 13: \t t-loss: 1.941339 \t t-acc: 0.271875 \t v-loss: 5.266075 \t v-acc: 0.021845 \t time: 3.112\n",
      "Epoch 14: \t t-loss: 1.896327 \t t-acc: 0.275000 \t v-loss: 5.442671 \t v-acc: 0.024120 \t time: 3.103\n",
      "Epoch 15: \t t-loss: 1.814681 \t t-acc: 0.303125 \t v-loss: 5.639101 \t v-acc: 0.029278 \t time: 3.096\n",
      "Epoch 16: \t t-loss: 1.773925 \t t-acc: 0.378125 \t v-loss: 5.686062 \t v-acc: 0.043083 \t time: 3.106\n",
      "Epoch 17: \t t-loss: 1.666117 \t t-acc: 0.415625 \t v-loss: 5.888085 \t v-acc: 0.042324 \t time: 3.099\n",
      "Epoch 18: \t t-loss: 1.577823 \t t-acc: 0.393750 \t v-loss: 6.448202 \t v-acc: 0.043538 \t time: 3.133\n",
      "Epoch 19: \t t-loss: 1.634871 \t t-acc: 0.390625 \t v-loss: 6.345906 \t v-acc: 0.042779 \t time: 3.112\n",
      "Epoch 20: \t t-loss: 1.493946 \t t-acc: 0.296875 \t v-loss: 5.629328 \t v-acc: 0.036408 \t time: 3.120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3aa2b668d7df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Train the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mepoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_vl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_va\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mESC3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maug_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Append lossed for confidence plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\HDA-Environmental-Sound-Classification\\ESC3.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, max_epochs, training_dataset, validation_dataset, batch_size, aug_rate, verbose)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;31m# train over mini-batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;31m# train on batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[0;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    700\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;31m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         dataset = _OptimizeDataset(dataset, graph_rewrites,\n\u001b[1;32m--> 387\u001b[1;33m                                    graph_rewrite_configs)\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[1;31m# (3) Apply autotune options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, optimizations, optimization_configs)\u001b[0m\n\u001b[0;32m   4398\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4399\u001b[0m         \u001b[0moptimization_configs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimization_configs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4400\u001b[1;33m         **self._flat_structure)\n\u001b[0m\u001b[0;32m   4401\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_OptimizeDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset\u001b[1;34m(input_dataset, optimizations, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[0;32m   3946\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3947\u001b[0m         \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_shapes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"optimization_configs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3948\u001b[1;33m         optimization_configs)\n\u001b[0m\u001b[0;32m   3949\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3950\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "max_epochs = 500\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "aug_rate=0.15\n",
    "\n",
    "# Loop over the functions\n",
    "for i in range(1, 6):\n",
    "    \n",
    "    \n",
    "    # load the fold data\n",
    "    train_d, train_l, val_d, val_l, test_d, test_l = ESC3.Load_Segments('ESC50', i)\n",
    "    \n",
    "    # Generate training and validation dataset\n",
    "    #training_dataset = ESC3.CreateTrainingSet50(train_d, train_l, name=f'train_F{i}', batch_size=batch_size)\n",
    "    training_dataset = ESC3.CreateValidationSet(train_d, train_l, name=f'train_F{i}', batch_size=batch_size)\n",
    "    validation_dataset = ESC3.CreateValidationSet(val_d, val_l, name=f'valid_F{i}', batch_size=batch_size)\n",
    "    \n",
    "    # Initialize the network\n",
    "    net = ESC3.PiczakNet50([60, 41, 3])\n",
    "    loss_f = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr)\n",
    "    net.compile(optimizer=opt, loss=loss_f, metrics=[\"accuracy\"])\n",
    "    \n",
    "    print(f'\\n#############################################################')\n",
    "    print(f'######################## FOLD-{i} #############################')\n",
    "    print(f'#############################################################')\n",
    "    \n",
    "    # Train the network\n",
    "    epoch_loss, epoch_acc, epoch_vl, epoch_va = ESC3.train(net, max_epochs, training_dataset, validation_dataset, batch_size=batch_size, aug_rate=aug_rate, verbose=True)\n",
    "    \n",
    "    # Append lossed for confidence plot\n",
    "    fold_train_loss.append(epoch_loss)\n",
    "    fold_train_accuracy.append(epoch_acc)\n",
    "    fold_valid_loss.append(epoch_vl)\n",
    "    fold_valid_accuracy.append(epoch_va)\n",
    "    \n",
    "    reset_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to array\n",
    "fold_train_loss = np.asarray(fold_train_loss)\n",
    "fold_train_accuracy = np.asarray(fold_train_accuracy)\n",
    "fold_valid_loss = np.asarray(fold_valid_loss)\n",
    "fold_valid_accuracy = np.asarray(fold_valid_accuracy)\n",
    "\n",
    "# Compute mean and confidence interval\n",
    "m_tl = []\n",
    "m_ta = []\n",
    "m_vl = []\n",
    "m_va = []\n",
    "\n",
    "ci_tl = []\n",
    "ci_ta = []\n",
    "ci_vl = []\n",
    "ci_va = []\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    m_tl.append(np.mean(fold_train_loss[:, i]))\n",
    "    m_ta.append(np.mean(fold_train_accuracy[:, i]))\n",
    "    m_vl.append(np.mean(fold_valid_loss[:, i]))\n",
    "    m_va.append(np.mean(fold_valid_accuracy[:, i]))\n",
    "    \n",
    "    ci_tl.append(1.96*np.std(fold_train_loss[:, i])/np.mean(fold_train_loss[:, i]))\n",
    "    ci_ta.append(1.96*np.std(fold_train_accuracy[:, i])/np.mean(fold_train_accuracy[:, i]))\n",
    "    ci_vl.append(1.96*np.std(fold_valid_loss[:, i])/np.mean(fold_valid_loss[:, i]))\n",
    "    ci_va.append(1.96*np.std(fold_valid_accuracy[:, i])/np.mean(fold_valid_accuracy[:, i]))\n",
    "\n",
    "m_tl = np.asarray(m_tl)\n",
    "m_ta = np.asarray(m_ta)\n",
    "m_vl = np.asarray(m_vl)\n",
    "m_va = np.asarray(m_va)\n",
    "\n",
    "ci_tl = np.asarray(ci_tl)\n",
    "ci_ta = np.asarray(ci_ta)\n",
    "ci_vl = np.asarray(ci_vl)\n",
    "ci_va = np.asarray(ci_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(m_tl, label='train loss')\n",
    "ax.fill_between(np.arange(0, max_epochs), (m_tl-ci_tl), (m_tl+ci_tl), color='b', alpha=.1)\n",
    "ax.plt(m_vl, label='validation loss')\n",
    "ax.fill_between(np.arange(0, max_epochs), (m_vl-ci_vl), (m_vl+ci_vl), color='r', alpha=.1)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(m_ta, label='train accuracy')\n",
    "ax.fill_between(np.arange(0, max_epochs), (m_ta-ci_ta), (m_ta+ci_ta), color='b', alpha=.1)\n",
    "ax.plt(m_va, label='validation accuracy')\n",
    "ax.fill_between(np.arange(0, max_epochs), (m_va-ci_va), (m_va+ci_va), color='r', alpha=.1)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Accuracy Plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
