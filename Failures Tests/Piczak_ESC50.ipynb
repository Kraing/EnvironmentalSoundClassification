{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "level-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16299901664646926992\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2219980313822134361\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7046801664\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6466868671250054945\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12055696645321016258\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ESC2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-discussion",
   "metadata": {},
   "source": [
    "## Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acting-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_train_loss = []\n",
    "fold_train_accuracy = []\n",
    "fold_valid_loss = []\n",
    "fold_valid_accuracy = []\n",
    "fold_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "waiting-louisville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############################################################\n",
      "######################## FOLD-1 #############################\n",
      "###############################################################\n",
      "Epoch  1: \t t-loss: 3.574240 \t t-acc: 0.062547 \t v-loss: 3.306976 \t v-acc: 0.109003 \t time: 176.292\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-778d6ec44c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Train the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mepoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_vl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_va\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mESC2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maug_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Append lossed for confidence plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\HDA-Environmental-Sound-Classification\\ESC2.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, max_epochs, training_dataset, validation_dataset, aug_rate, verbose)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;31m# convert to melspectrogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m             \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCompute_MelSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;31m# scale to 0 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\HDA-Environmental-Sound-Classification\\ESC2.py\u001b[0m in \u001b[0;36mCompute_MelSpec\u001b[1;34m(dataset, bands)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msegment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamplitude_to_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[0mlog_specgrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbands\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m41\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\librosa\\feature\\spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2008\u001b[0m     \u001b[1;31m# Build a Mel filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2009\u001b[1;33m     \u001b[0mmel_basis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2011\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmel_basis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\librosa\\filters.py\u001b[0m in \u001b[0;36mmel\u001b[1;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# .. then intersect them with each other and zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"slaney\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "max_epochs = 50\n",
    "lr = 0.0001\n",
    "batch_size = 64\n",
    "aug_rate=0.15\n",
    "\n",
    "# Loop over the functions\n",
    "for i in range(1, 6):\n",
    "    \n",
    "    print(f'\\n###############################################################')\n",
    "    print(f'######################## FOLD-{i} #############################')\n",
    "    print(f'###############################################################')\n",
    "    # load the fold data\n",
    "    train_d, train_l, val_d, val_l, test_d, test_l = ESC2.Load_Segments('ESC50', i)\n",
    "    \n",
    "    # Generate training and validation dataset\n",
    "    training_dataset = ESC2.CreateTrainingSet50(train_d, train_l, name=f'train_F{i}', batch_size=batch_size)\n",
    "    validation_dataset = ESC2.CreateValidationSet(val_d, val_l, name=f'valid_F{i}', batch_size=batch_size)\n",
    "    \n",
    "    # Initialize the network\n",
    "    net = ESC2.PiczakNet50([60, 41, 2])\n",
    "    loss_f = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr)\n",
    "    net.compile(optimizer=opt, loss=loss_f, metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Train the network\n",
    "    epoch_loss, epoch_acc, epoch_vl, epoch_va = ESC2.train(net, max_epochs, training_dataset, validation_dataset, aug_rate=aug_rate, verbose=True)\n",
    "    \n",
    "    # Append lossed for confidence plot\n",
    "    fold_train_loss.append(epoch_loss)\n",
    "    fold_train_accuracy.append(epoch_acc)\n",
    "    fold_valid_loss.append(epoch_vl)\n",
    "    fold_valid_accuracy.append(epoch_va)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to array\n",
    "fold_train_loss = np.asarray(fold_train_loss)\n",
    "fold_train_accuracy = np.asarray(fold_train_accuracy)\n",
    "fold_valid_loss = np.asarray(fold_valid_loss)\n",
    "fold_valid_accuracy = np.asarray(fold_valid_accuracy)\n",
    "\n",
    "# Compute mean and confidence interval\n",
    "m_tl = []\n",
    "m_ta = []\n",
    "m_vl = []\n",
    "m_va = []\n",
    "\n",
    "ci_tl = []\n",
    "ci_ta = []\n",
    "ci_vl = []\n",
    "ci_va = []\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    m_tl.append(np.mean(fold_train_loss[:, i]))\n",
    "    m_ta.append(np.mean(fold_train_accuracy[:, i]))\n",
    "    m_vl.append(np.mean(fold_valid_loss[:, i]))\n",
    "    m_va.append(np.mean(fold_valid_accuracy[:, i]))\n",
    "    \n",
    "    ci_tl.append(1.96*np.std(fold_train_loss[:, i])/np.mean(fold_train_loss[:, i]))\n",
    "    ci_ta.append(1.96*np.std(fold_train_accuracy[:, i])/np.mean(fold_train_accuracy[:, i]))\n",
    "    ci_vl.append(1.96*np.std(fold_valid_loss[:, i])/np.mean(fold_valid_loss[:, i]))\n",
    "    ci_va.append(1.96*np.std(fold_valid_accuracy[:, i])/np.mean(fold_valid_accuracy[:, i]))\n",
    "\n",
    "m_tl = np.asarray(m_tl)\n",
    "m_ta = np.asarray(m_ta)\n",
    "m_vl = np.asarray(m_vl)\n",
    "m_va = np.asarray(m_va)\n",
    "\n",
    "ci_tl = np.asarray(ci_tl)\n",
    "ci_ta = np.asarray(ci_ta)\n",
    "ci_vl = np.asarray(ci_vl)\n",
    "ci_va = np.asarray(ci_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(m_tl, label='train loss')\n",
    "ax.fill_between(np.arange(0, max_epochs), (m_tl-ci_tl), (m_tl+ci_tl), color='b', alpha=.1)\n",
    "ax.plot(m_vl, label='validation loss')\n",
    "ax.fill_between(np.arange(0, max_epochs), (m_vl-ci_vl), (m_vl+ci_vl), color='r', alpha=.1)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(m_ta, label='train accuracy')\n",
    "ax.fill_between(np.arange(0, max_epochs), (m_ta-ci_ta), (m_ta+ci_ta), color='b', alpha=.1)\n",
    "ax.plot(m_va, label='validation accuracy')\n",
    "ax.fill_between(np.arange(0, max_epochs), (m_va-ci_va), (m_va+ci_va), color='r', alpha=.1)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Accuracy Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best point before overfit on each run\n",
    "\n",
    "# Retrain the network until that point\n",
    "\n",
    "# Evaluate on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
