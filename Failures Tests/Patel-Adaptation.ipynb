{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "motivated-invite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5277043790688170713\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1016081477195794080\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7046801664\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12825400588471198616\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4435495250952253723\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "import ESC\n",
    "\n",
    "# Use GPU\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accurate-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield int(start), int(start + window_size)\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features(raw_data, label, bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    labels = []\n",
    "    \n",
    "    for num, audio in enumerate(tqdm(raw_data)):\n",
    "        #sound_clip, s = librosa.load(fn) # 5sec\n",
    "        #sound_clip   = np.concatenate((sound_clip,sound_clip),axis=None) # make it 10s\n",
    "        #label = fn.split(\"/\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "        for (start,end) in windows(audio,window_size):\n",
    "            if(len(audio[start:end]) == window_size):\n",
    "                signal = audio[start:end]\n",
    "                melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                logspec = librosa.core.amplitude_to_db(melspec)\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                log_specgrams.append(logspec)\n",
    "                labels.append(label[num])\n",
    "            \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features), np.array(labels,dtype = np.int)\n",
    "\n",
    "def extract_features_original(bands=60, frames=41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    cvs = []\n",
    "    labels = []\n",
    "    for fn in tqdm(glob('audio/*')):\n",
    "        sound_clip,s = librosa.load(fn) # 5sec\n",
    "        #sound_clip   = np.concatenate((sound_clip,sound_clip),axis=None) # make it 10s\n",
    "        \n",
    "        # Split the file name\n",
    "        name_splitted = fn.split(\"\\\\\")\n",
    "        name_splitted = re.split('[\\-.]', name_splitted[1])\n",
    "\n",
    "        # Append a row of 3 elements\n",
    "        fold = name_splitted[0]\n",
    "        label = name_splitted[3]\n",
    "        \n",
    "        #label = fn.split(\"/\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "        for (start,end) in windows(sound_clip,window_size):\n",
    "            if(len(sound_clip[start:end]) == window_size):\n",
    "                signal = sound_clip[start:end]\n",
    "                melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                logspec = librosa.core.amplitude_to_db(melspec)\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                log_specgrams.append(logspec)\n",
    "                labels.append(label)\n",
    "                cvs.append(fold)\n",
    "            \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features), np.array(labels, dtype=np.int), np.array(cvs, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ongoing-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '100032', 'A', '0', 'wav']\n"
     ]
    }
   ],
   "source": [
    "file = glob('audio/*')\n",
    "\n",
    "f = file[0].split(\"\\\\\")\n",
    "f[1] = re.split('[\\\\-.]', f[1])\n",
    "print(f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hybrid-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [06:34<00:00,  5.07it/s]\n",
      "100%|██████████| 18000/18000 [00:00<00:00, 486493.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds size: 3600 - 3600 - 3600 - 3600 - 3600\n",
      "Folds sample shape:  2\n",
      "Folds sample data shape:  (60, 41, 2)\n",
      "Folds sample label type:  ()\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "'''\n",
    "PATH = 'audio'\n",
    "raw_files, cvs, labels = ESC.Load_RAW(PATH)\n",
    "\n",
    "# Split the different folds\n",
    "f1, f2, f3, f4, f5 = ESC.Split_Folds(raw_files, cvs, labels, verbose=True)\n",
    "\n",
    "# Load\n",
    "af1, alf1 = ESC.Split_Data_Label(f1)\n",
    "af2, alf2 = ESC.Split_Data_Label(f2)\n",
    "af3, alf3 = ESC.Split_Data_Label(f3)\n",
    "af4, alf4 = ESC.Split_Data_Label(f4)\n",
    "af5, alf5 = ESC.Split_Data_Label(f5)\n",
    "'''\n",
    "\n",
    "features, labels, cvs = extract_features_original()\n",
    "\n",
    "# Split the different folds\n",
    "f1, f2, f3, f4, f5 = ESC.Split_Folds(features, cvs, labels, verbose=True)\n",
    "\n",
    "# Load\n",
    "af1, alf1 = ESC.Split_Data_Label(f1)\n",
    "af2, alf2 = ESC.Split_Data_Label(f2)\n",
    "af3, alf3 = ESC.Split_Data_Label(f3)\n",
    "af4, alf4 = ESC.Split_Data_Label(f4)\n",
    "af5, alf5 = ESC.Split_Data_Label(f5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wireless-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf1_processed = to_categorical(alf1, num_classes=50)\n",
    "lf2_processed = to_categorical(alf2, num_classes=50)\n",
    "lf3_processed = to_categorical(alf3, num_classes=50)\n",
    "lf4_processed = to_categorical(alf4, num_classes=50)\n",
    "lf5_processed = to_categorical(alf5, num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "applicable-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the features\n",
    "f1_processed, lf1_processed = af1, lf1_processed\n",
    "f2_processed, lf2_processed = af2, lf2_processed\n",
    "f3_processed, lf3_processed = af3, lf3_processed\n",
    "f4_processed, lf4_processed = af4, lf4_processed\n",
    "f5_processed, lf5_processed = af5, lf5_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "measured-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle each folder\n",
    "\n",
    "rnd_indices = np.arange(0, len(f1_processed))\n",
    "rnd_indices = np.random.shuffle(rnd_indices)\n",
    "\n",
    "f1_processed = f1_processed[rnd_indices].reshape((len(f1_processed), 60, 41, 2))\n",
    "lf1_processed = lf1_processed[rnd_indices].reshape((len(lf1_processed), 50))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "innocent-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_indices = np.arange(0, len(f2_processed))\n",
    "rnd_indices = np.random.shuffle(rnd_indices)\n",
    "\n",
    "f2_processed = f2_processed[rnd_indices].reshape((len(f2_processed), 60, 41, 2))\n",
    "lf2_processed = lf2_processed[rnd_indices].reshape((len(lf2_processed), 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continued-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_indices = np.arange(0, len(f3_processed))\n",
    "rnd_indices = np.random.shuffle(rnd_indices)\n",
    "\n",
    "f3_processed = f3_processed[rnd_indices].reshape((len(f3_processed), 60, 41, 2))\n",
    "lf3_processed = lf3_processed[rnd_indices].reshape((len(lf3_processed), 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "measured-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_indices = np.arange(0, len(f4_processed))\n",
    "rnd_indices = np.random.shuffle(rnd_indices)\n",
    "\n",
    "f4_processed = f4_processed[rnd_indices].reshape((len(f4_processed), 60, 41, 2))\n",
    "lf4_processed = lf4_processed[rnd_indices].reshape((len(lf4_processed), 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suburban-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_indices = np.arange(0, len(f5_processed))\n",
    "rnd_indices = np.random.shuffle(rnd_indices)\n",
    "\n",
    "f5_processed = f5_processed[rnd_indices].reshape((len(f5_processed), 60, 41, 2))\n",
    "lf5_processed = lf5_processed[rnd_indices].reshape((len(lf5_processed), 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numeric-potter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf1_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label category names\n",
    "'''\n",
    "df = pd.read_csv(glob('meta/esc50.csv')[0])\n",
    "df = df[['target','category']]\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df = df.sort_values(by=['target']).reset_index(drop=True)\n",
    "df.head()\n",
    "\n",
    "my_dict = {}\n",
    "for i in range(len(df)):\n",
    "    my_dict[df['target'][i]] = df['category'][i]\n",
    "my_dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot_labels = to_categorical(labels,num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train test Dataset\n",
    "#rnd_indices = np.random.rand(len(labels)) < 0.70\n",
    "\n",
    "#X_train = features[rnd_indices]\n",
    "#y_train = onehot_labels[rnd_indices]\n",
    "#X_test  = features[~rnd_indices]\n",
    "#y_test  = onehot_labels[~rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-shirt",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solar-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten,InputLayer\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def basemodel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(60,41,2), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='softmax'))\n",
    "    # Compile model\n",
    "    epochs = 25\n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "#     sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consistent-first",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 60, 41, 32)        608       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 41, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 41, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              4588544   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                25650     \n",
      "=================================================================\n",
      "Total params: 5,425,714\n",
      "Trainable params: 5,425,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = basemodel()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-conversion",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dynamic-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTrainingSet(f1, lf1, batch_size=32):\n",
    "    \n",
    "\n",
    "    # Create dataset\n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((f1, lf1))\n",
    "    \n",
    "    # Cache the dataset\n",
    "    training_dataset = training_dataset.cache(\"training_cache\")\n",
    "    \n",
    "    # Shuffle all elements at every iteration\n",
    "    training_dataset = training_dataset.shuffle(len(training_dataset))\n",
    "    \n",
    "    # Define batch_size and prefetch size\n",
    "    training_dataset = training_dataset.batch(batch_size=batch_size).prefetch(buffer_size=1)\n",
    "    \n",
    "    return training_dataset\n",
    "\n",
    "\n",
    "def CreateValidationSet(f1, lf1, batch_size=32):\n",
    "    \n",
    "    f1 = f1.astype(dtype=np.float32)\n",
    "    lf1 = lf1.astype(dtype=np.float32)\n",
    "    \n",
    "    # Create and cache training\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((f1, lf1))\n",
    "    \n",
    "    # Cache dataset\n",
    "    validation_dataset = validation_dataset.cache(\"validation_cache\")\n",
    "    \n",
    "    # Shuffle all elements at every iteration\n",
    "    #validation_dataset = validation_dataset.shuffle(len(validation_dataset))\n",
    "    \n",
    "    # Define batch_size and prefetch size\n",
    "    validation_dataset = validation_dataset.batch(batch_size=batch_size).prefetch(buffer_size=1)\n",
    "    \n",
    "    return validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tutorial-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ESC\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "\n",
    "#training_set = CreateTrainingSet(X_train, y_train, batch_size=batch_size)\n",
    "#validation_set = CreateValidationSet(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "training_dataset = ESC.CreateTrainingSet(f1_processed, f4_processed, f5_processed, lf1_processed, lf4_processed, lf5_processed, batch_size=128)\n",
    "\n",
    "validation_dataset = ESC.CreateValidationSet(f3_processed, lf3_processed, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterat = iter(training_dataset)\n",
    "tmp = next(iterat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTrainingSet(f1, f2, f3, lf1, lf2, lf3, batch_size=32):\n",
    "    \n",
    "    # Create training set\n",
    "    merged_training_data = np.concatenate((f1, f2, f3))\n",
    "    merged_training_label = np.concatenate((lf1, lf2, lf3))\n",
    "    \n",
    "    # Shuffle the folds\n",
    "    rnd_indices = np.arange(0, len(merged_training_data))\n",
    "    rnd_indices = np.random.shuffle(rnd_indices)\n",
    "    \n",
    "    merged_training_data = merged_training_data[rnd_indices].reshape((len(f1) + len(f2) + len(f3), 60, 41, 2))\n",
    "    merged_training_label = merged_training_label[rnd_indices].reshape((len(f1) + len(f2) + len(f3), 50))\n",
    "    \n",
    "    print(merged_training_data.shape)\n",
    "    \n",
    "    merged_training_data = merged_training_data.astype(np.float32)\n",
    "    merged_training_label = merged_training_label.astype(np.float32)\n",
    "\n",
    "    # Create dataset\n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((merged_training_data, merged_training_label))\n",
    "    \n",
    "    # Cache the dataset\n",
    "    training_dataset = training_dataset.cache(\"training_cache\")\n",
    "    \n",
    "    # Shuffle all elements at every iteration\n",
    "    training_dataset = training_dataset.shuffle(len(training_dataset))\n",
    "    \n",
    "    # Define batch_size and prefetch size\n",
    "    training_dataset = training_dataset.batch(batch_size=batch_size).prefetch(buffer_size=1)\n",
    "    \n",
    "    return training_dataset\n",
    "\n",
    "training_dataset = ESC.CreateTrainingSet(f1_processed, f4_processed, f5_processed, lf1_processed, lf4_processed, lf5_processed, batch_size=128)\n",
    "validation_dataset = ESC.CreateValidationSet(f3_processed, lf3_processed, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "novel-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 7.5541 - accuracy: 0.0312 - val_loss: 4.0388 - val_accuracy: 0.0200\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 4.6155 - accuracy: 0.0195 - val_loss: 3.9203 - val_accuracy: 0.0183\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.9761 - accuracy: 0.0234 - val_loss: 3.9148 - val_accuracy: 0.0200\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 3.9181 - accuracy: 0.0234 - val_loss: 3.9128 - val_accuracy: 0.0186\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 3.9193 - accuracy: 0.0078 - val_loss: 3.9116 - val_accuracy: 0.0278\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 3.9065 - accuracy: 0.0352 - val_loss: 3.9115 - val_accuracy: 0.0206\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.9053 - accuracy: 0.0234 - val_loss: 3.9115 - val_accuracy: 0.0156\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.9154 - accuracy: 0.0156 - val_loss: 3.9117 - val_accuracy: 0.0172\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.8972 - accuracy: 0.0234 - val_loss: 3.9120 - val_accuracy: 0.0225\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 3.9134 - accuracy: 0.0195 - val_loss: 3.9119 - val_accuracy: 0.0247\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.9162 - accuracy: 0.0117 - val_loss: 3.9117 - val_accuracy: 0.0197\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 3.9022 - accuracy: 0.0234 - val_loss: 3.9115 - val_accuracy: 0.0200\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 3.9066 - accuracy: 0.0117 - val_loss: 3.9112 - val_accuracy: 0.0200\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 3.9025 - accuracy: 0.0117 - val_loss: 3.9099 - val_accuracy: 0.0217\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.8923 - accuracy: 0.0156 - val_loss: 3.9070 - val_accuracy: 0.0208\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.8875 - accuracy: 0.0352 - val_loss: 3.9046 - val_accuracy: 0.0214\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 3.8924 - accuracy: 0.0117 - val_loss: 3.9087 - val_accuracy: 0.0381\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.8524 - accuracy: 0.0273 - val_loss: 3.9010 - val_accuracy: 0.0431\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.8374 - accuracy: 0.0195 - val_loss: 3.8798 - val_accuracy: 0.0369\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 3.8477 - accuracy: 0.0156 - val_loss: 3.9008 - val_accuracy: 0.0397\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 3.8198 - accuracy: 0.0234 - val_loss: 3.8972 - val_accuracy: 0.0475\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 3.8054 - accuracy: 0.0234 - val_loss: 3.8558 - val_accuracy: 0.0472\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 3.8199 - accuracy: 0.0391 - val_loss: 3.8693 - val_accuracy: 0.0422\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 3.7972 - accuracy: 0.0312 - val_loss: 3.8840 - val_accuracy: 0.0389\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 3.8033 - accuracy: 0.0273 - val_loss: 3.8667 - val_accuracy: 0.0364\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.8258 - accuracy: 0.0352 - val_loss: 3.8563 - val_accuracy: 0.0367\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 3.7401 - accuracy: 0.0312 - val_loss: 3.8509 - val_accuracy: 0.0378\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 3.8173 - accuracy: 0.0156 - val_loss: 3.8474 - val_accuracy: 0.0358\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.7416 - accuracy: 0.0430 - val_loss: 3.8127 - val_accuracy: 0.0325\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.8096 - accuracy: 0.0312 - val_loss: 3.7900 - val_accuracy: 0.0339\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 3.6819 - accuracy: 0.0234 - val_loss: 3.7618 - val_accuracy: 0.0350\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.7181 - accuracy: 0.0156 - val_loss: 3.7552 - val_accuracy: 0.0361\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.6410 - accuracy: 0.0312 - val_loss: 3.7567 - val_accuracy: 0.0336\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.6633 - accuracy: 0.0352 - val_loss: 3.7551 - val_accuracy: 0.0350\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 3.6711 - accuracy: 0.0352 - val_loss: 3.7554 - val_accuracy: 0.0356\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 3.6902 - accuracy: 0.0234 - val_loss: 3.7426 - val_accuracy: 0.0339\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.6379 - accuracy: 0.0625 - val_loss: 3.7275 - val_accuracy: 0.0375\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 3.6242 - accuracy: 0.0352 - val_loss: 3.7069 - val_accuracy: 0.0383\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.6232 - accuracy: 0.0312 - val_loss: 3.6912 - val_accuracy: 0.0422\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.6334 - accuracy: 0.0352 - val_loss: 3.6863 - val_accuracy: 0.0428\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.6350 - accuracy: 0.0352 - val_loss: 3.6781 - val_accuracy: 0.0417\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.5912 - accuracy: 0.0352 - val_loss: 3.6720 - val_accuracy: 0.0431\n",
      "Epoch 43/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.5539 - accuracy: 0.0417WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
      "1/2 [==============>...............] - 0s 377ms/step - loss: 3.5539 - accuracy: 0.0417 - val_loss: 3.6589 - val_accuracy: 0.0431\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "              width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "              height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "              horizontal_flip=True,  # randomly flip images\n",
    "              vertical_flip=False  # randomly flip images\n",
    "          )\n",
    "\n",
    "\n",
    "history = model.fit(training_dataset,\n",
    "                      steps_per_epoch=int(np.ceil(len(training_dataset) / float(batch_size))),\n",
    "                      epochs=100,\n",
    "                      validation_data=validation_dataset,\n",
    "                      verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-onion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-syracuse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
