{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unable-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ESC3\n",
    "import multiprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "timely-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PiczakNet50(input_shape):\n",
    "    \n",
    "    X_input = tf.keras.Input(input_shape)\n",
    "    \n",
    "    # First convolution block\n",
    "    model = tf.keras.layers.Conv2D(80, kernel_size=(57, 6), strides=1, padding='same', name='conv0')(X_input)\n",
    "    model = tf.keras.layers.Activation('relu')(model)\n",
    "    model = tf.keras.layers.MaxPool2D(pool_size=(4, 3), strides=(1, 3), padding='same')(model)\n",
    "    model = tf.keras.layers.Dropout(0.5)(model)\n",
    "    \n",
    "    # Second convolution block\n",
    "    model = tf.keras.layers.Conv2D(80, kernel_size=(1, 3), strides=1, padding='same', name='conv1')(model)\n",
    "    model = tf.keras.layers.Activation('relu')(model)\n",
    "    model = tf.keras.layers.MaxPool2D(pool_size=(1, 3), strides=(1, 3), padding='same')(model)\n",
    "    \n",
    "    # Flatten\n",
    "    model = tf.keras.layers.Flatten()(model)\n",
    "    \n",
    "    # First fully-connected block\n",
    "    model = tf.keras.layers.Dense(5000, activation='relu', name='fc0')(model)\n",
    "    model = tf.keras.layers.Dropout(0.5)(model)\n",
    "    \n",
    "    # Second fully-connected block\n",
    "    model = tf.keras.layers.Dense(5000, activation='relu', name='fc1')(model)\n",
    "    model = tf.keras.layers.Dropout(0.5)(model)\n",
    "    \n",
    "    # Output layer\n",
    "    model = tf.keras.layers.Dense(50, activation=None, name='out')(model)\n",
    "    \n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = model, name='PiczakNet50')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def CreateTrainingSet50(data, label, name='', batch_size=32):\n",
    "    \n",
    "    # Shuffle the folds\n",
    "    rnd_indices = np.arange(0, len(data))\n",
    "    rnd_indices = np.random.shuffle(rnd_indices)\n",
    "    \n",
    "    data = data[rnd_indices].reshape((len(data), 60, 41, 3))\n",
    "    label = label[rnd_indices].reshape((len(label), 50))\n",
    "    \n",
    "    \n",
    "    data = data.astype(np.float32)\n",
    "    label = label.astype(np.float32)\n",
    "    \n",
    "    '''\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0,\n",
    "                                                              height_shift_range=0,\n",
    "                                                              horizontal_flip=False,\n",
    "                                                              vertical_flip=False) \n",
    "    \n",
    "    # Shuffle all elements at every iteration\n",
    "    training_dataset = datagen.flow(data, label, batch_size=batch_size, shuffle=True)\n",
    "    '''\n",
    "    \n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "    \n",
    "    # Shuffle all elements at every iteration\n",
    "    training_dataset = training_dataset.shuffle(len(training_dataset))\n",
    "    \n",
    "    # Define batch_size and prefetch size\n",
    "    training_dataset = training_dataset.batch(batch_size=batch_size).prefetch(buffer_size=1)\n",
    "    \n",
    "    return training_dataset\n",
    "\n",
    "\n",
    "def CreateValidationSet(data, label, name='', batch_size=32):\n",
    "    \n",
    "    data = data.astype(dtype=np.float32)\n",
    "    label = label.astype(dtype=np.float32)\n",
    "    \n",
    "    # Create and cache training\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "    \n",
    "    # Cache dataset\n",
    "    #validation_dataset = validation_dataset.cache(name)\n",
    "    \n",
    "    # Define batch_size and prefetch size\n",
    "    validation_dataset = validation_dataset.batch(batch_size=batch_size).prefetch(buffer_size=1)\n",
    "    \n",
    "    return validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hired-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "train_d, train_l, val_d, val_l, test_d, test_l = ESC3.Load_Segments('ESC50', 1)\n",
    "\n",
    "training_dataset = CreateTrainingSet50(train_d, train_l, name=f'train_F', batch_size=batch_size)\n",
    "validation_dataset = CreateValidationSet(train_d, train_l, name=f'train_F', batch_size=batch_size)\n",
    "    \n",
    "# Initialize the network\n",
    "net = PiczakNet50([60, 41, 3])\n",
    "loss_f = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "net.compile(optimizer=opt, loss=loss_f, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: \t t-loss: 3.924480 \t t-acc: 0.018750 \t v-loss: 3.913088 \t v-acc: 0.021006 \t time: 10.971\n",
      "Epoch  2: \t t-loss: 3.922179 \t t-acc: 0.018750 \t v-loss: 3.911727 \t v-acc: 0.021006 \t time: 9.255\n",
      "Epoch  3: \t t-loss: 3.917253 \t t-acc: 0.025000 \t v-loss: 3.910533 \t v-acc: 0.023231 \t time: 9.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x000001DF0B1E9E58>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ax09\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 537, in __del__\n",
      "    handle=self._handle, deleter=self._deleter)\n",
      "  File \"C:\\Users\\Ax09\\Anaconda3\\envs\\tf_gpu_hda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1279, in delete_iterator\n",
      "    tld.op_callbacks, handle, deleter)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4: \t t-loss: 3.926134 \t t-acc: 0.021875 \t v-loss: 3.909605 \t v-acc: 0.022403 \t time: 9.197\n",
      "Epoch  5: \t t-loss: 3.908404 \t t-acc: 0.021875 \t v-loss: 3.908722 \t v-acc: 0.022351 \t time: 9.167\n",
      "Epoch  6: \t t-loss: 3.910438 \t t-acc: 0.015625 \t v-loss: 3.907962 \t v-acc: 0.021730 \t time: 9.147\n",
      "Epoch  7: \t t-loss: 3.921241 \t t-acc: 0.028125 \t v-loss: 3.907517 \t v-acc: 0.024265 \t time: 9.060\n",
      "Epoch  8: \t t-loss: 3.906324 \t t-acc: 0.018750 \t v-loss: 3.906901 \t v-acc: 0.023231 \t time: 9.065\n",
      "Epoch  9: \t t-loss: 3.911426 \t t-acc: 0.028125 \t v-loss: 3.906878 \t v-acc: 0.022351 \t time: 9.090\n",
      "Epoch 10: \t t-loss: 3.908517 \t t-acc: 0.031250 \t v-loss: 3.906219 \t v-acc: 0.022351 \t time: 9.004\n",
      "Epoch 11: \t t-loss: 3.905114 \t t-acc: 0.015625 \t v-loss: 3.905577 \t v-acc: 0.022351 \t time: 9.013\n",
      "Epoch 12: \t t-loss: 3.915838 \t t-acc: 0.006250 \t v-loss: 3.904896 \t v-acc: 0.022351 \t time: 9.143\n",
      "Epoch 13: \t t-loss: 3.902696 \t t-acc: 0.012500 \t v-loss: 3.903943 \t v-acc: 0.013297 \t time: 9.105\n",
      "Epoch 14: \t t-loss: 3.907361 \t t-acc: 0.015625 \t v-loss: 3.903551 \t v-acc: 0.024834 \t time: 8.948\n",
      "Epoch 15: \t t-loss: 3.895218 \t t-acc: 0.015625 \t v-loss: 3.902917 \t v-acc: 0.022351 \t time: 9.010\n",
      "Epoch 16: \t t-loss: 3.907909 \t t-acc: 0.006250 \t v-loss: 3.902010 \t v-acc: 0.033061 \t time: 8.851\n",
      "Epoch 17: \t t-loss: 3.910042 \t t-acc: 0.015625 \t v-loss: 3.901815 \t v-acc: 0.033889 \t time: 8.807\n",
      "Epoch 18: \t t-loss: 3.913409 \t t-acc: 0.021875 \t v-loss: 3.901517 \t v-acc: 0.035493 \t time: 8.790\n",
      "Epoch 19: \t t-loss: 3.898559 \t t-acc: 0.028125 \t v-loss: 3.901129 \t v-acc: 0.025921 \t time: 8.784\n",
      "Epoch 20: \t t-loss: 3.902811 \t t-acc: 0.021875 \t v-loss: 3.900135 \t v-acc: 0.033785 \t time: 8.836\n",
      "Epoch 21: \t t-loss: 3.904001 \t t-acc: 0.031250 \t v-loss: 3.899275 \t v-acc: 0.031043 \t time: 8.918\n",
      "Epoch 22: \t t-loss: 3.890072 \t t-acc: 0.040625 \t v-loss: 3.897712 \t v-acc: 0.023179 \t time: 8.975\n",
      "Epoch 23: \t t-loss: 3.894193 \t t-acc: 0.021875 \t v-loss: 3.896241 \t v-acc: 0.022351 \t time: 8.944\n",
      "Epoch 24: \t t-loss: 3.893740 \t t-acc: 0.025000 \t v-loss: 3.895097 \t v-acc: 0.022661 \t time: 8.876\n",
      "Epoch 25: \t t-loss: 3.889426 \t t-acc: 0.031250 \t v-loss: 3.894095 \t v-acc: 0.024162 \t time: 8.977\n",
      "Epoch 26: \t t-loss: 3.884418 \t t-acc: 0.040625 \t v-loss: 3.892636 \t v-acc: 0.025559 \t time: 8.857\n",
      "Epoch 27: \t t-loss: 3.889139 \t t-acc: 0.028125 \t v-loss: 3.891523 \t v-acc: 0.021885 \t time: 8.855\n",
      "Epoch 28: \t t-loss: 3.898808 \t t-acc: 0.025000 \t v-loss: 3.891079 \t v-acc: 0.022092 \t time: 8.861\n",
      "Epoch 29: \t t-loss: 3.877746 \t t-acc: 0.028125 \t v-loss: 3.889149 \t v-acc: 0.021989 \t time: 8.833\n",
      "Epoch 30: \t t-loss: 3.884280 \t t-acc: 0.021875 \t v-loss: 3.886880 \t v-acc: 0.021989 \t time: 9.027\n"
     ]
    }
   ],
   "source": [
    "max_epochs=50\n",
    "epoch_loss, epoch_acc, epoch_vl, epoch_va = ESC3.train(net, max_epochs, training_dataset, validation_dataset, batch_size, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-portland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
