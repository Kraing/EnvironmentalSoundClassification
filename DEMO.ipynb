{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-pixel",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_ESC10(path):\n",
    "    '''\n",
    "        Input:\n",
    "            path: folder of the dataset\n",
    "        \n",
    "        Output:\n",
    "            raw_data:  list that contains the raw data\n",
    "            cvs:       list that contains the cross-fold number\n",
    "            labels:    list that contains the category information\n",
    "    '''\n",
    "    \n",
    "    # Container for the dataset\n",
    "    raw_data = []\n",
    "    cvs = []\n",
    "    labels = []\n",
    "\n",
    "    # Extract ESC10 files name\n",
    "    df = pd.read_csv(glob('meta/esc50.csv')[0])\n",
    "\n",
    "    # filter columns\n",
    "    df = df[['filename', 'esc10']]\n",
    "\n",
    "    # Load every file inside the folder\n",
    "    for file_name in tqdm(os.listdir(path)):\n",
    "\n",
    "        # Check if file_name is an esc10\n",
    "        row = df[df['filename']==file_name]\n",
    "        check = row.esc10.iloc[0]\n",
    "\n",
    "        if check==True:    \n",
    "            try:\n",
    "                # Get audio data and sampling rate\n",
    "                audio, sampling_rate = librosa.load(os.path.join(path, file_name), res_type='kaiser_fast')\n",
    "\n",
    "                # Split the file name\n",
    "                name_splitted = re.split('[-.]', file_name)\n",
    "\n",
    "                # Append a row of 3 elements\n",
    "                raw_data.append(audio)\n",
    "                cvs.append(name_splitted[0])\n",
    "                labels.append(name_splitted[3])\n",
    "                                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "    raw_audio = np.asarray(raw_data)\n",
    "    cvs = np.asarray(cvs, dtype=int)\n",
    "    labels = np.asarray(labels, dtype=int)\n",
    "\n",
    "    return raw_audio, cvs, labels\n",
    "\n",
    "# Split dataset into data and labels\n",
    "def Split_Data_Label(dataset):\n",
    "    \n",
    "    \n",
    "    data = []\n",
    "    label = []\n",
    "        \n",
    "    for i in range (len(dataset)):\n",
    "        data.append(dataset[i][0])\n",
    "        label.append(dataset[i][1])\n",
    "\n",
    "    \n",
    "    data = np.asarray(data)\n",
    "    label = np.asarray(label)\n",
    "    \n",
    "    return data, label\n",
    "\n",
    "def Merge_Data_Label(raw_audio, labels):\n",
    "    \n",
    "    dataset = []\n",
    "    # Loop over each file audio\n",
    "    for num, audio in enumerate(tqdm(raw_audio)):\n",
    "\n",
    "        dataset.append((audio, labels[num]))\n",
    "\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    dataset = np.asarray(dataset, dtype=object)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def label_map(label):\n",
    "    \n",
    "    unique = np.unique(label)\n",
    "    new_labels = np.arange(0, len(unique))\n",
    "    \n",
    "    for i in range(len(unique)):\n",
    "        \n",
    "        comp = unique[i]\n",
    "        \n",
    "        for k in range(len(label)):\n",
    "            if label[k] == comp:\n",
    "                label[k] = new_labels[i]\n",
    "    \n",
    "    return label\n",
    "\n",
    "def Split_Segments(dataset, overlap=0.75, wnd=20480, threshold=10**-6):\n",
    "    \n",
    "    data, label = Split_Data_Label(dataset)\n",
    "\n",
    "    segment_list = []\n",
    "    label_list = []\n",
    "\n",
    "    # Loop over audio sample\n",
    "    for num, audio in enumerate(data):\n",
    "        for idx in range(0, len(audio) - int(wnd * overlap), int(wnd*(1 - overlap))):\n",
    "\n",
    "            segment = audio[idx:idx+wnd]\n",
    "            \n",
    "            check = np.mean(segment**2)\n",
    "            \n",
    "            if((check>threshold) and (len(segment)==wnd)):\n",
    "                segment_list.append(segment)\n",
    "                label_list.append(label[num])\n",
    "    \n",
    "    #print(len(segment_list))\n",
    "    segment_list = np.asarray(segment_list, dtype=np.float32)\n",
    "    label_list = np.asarray(label_list, dtype=np.float32)\n",
    "    \n",
    "    return segment_list, label_list\n",
    "\n",
    "def Compute_MelSpec3(dataset, bands=60):\n",
    "\n",
    "    features = []\n",
    "    for segment in dataset:\n",
    "        features.append(librosa.core.amplitude_to_db(librosa.feature.melspectrogram(segment, n_mels=bands)))\n",
    "    \n",
    "    log_specgrams = np.asarray(features).reshape(len(features), bands, 41, 1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams)), np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    \n",
    "    # compute delta_1\n",
    "    for i in range(len(log_specgrams)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "                              #compute delta_2\n",
    "    for i in range(len(log_specgrams)):\n",
    "        features[i, :, :, 2] = librosa.feature.delta(features[i, :, :, 1])\n",
    "                              \n",
    "    features = features.astype(np.float32)    \n",
    "    return features\n",
    "\n",
    "\n",
    "# Split loaded raw_data into folds\n",
    "def Split_Folds(raw_audio, cvs, labels, verbose=False):\n",
    "    '''\n",
    "        Input:\n",
    "            raw_audio: list that contains the raw data\n",
    "            cvs:       list that contains the cross-fold number\n",
    "            labels:    list that contains the category information\n",
    "            verbose:   flag used to print produced folds information\n",
    "        \n",
    "        Output:\n",
    "            f{1,2,3,4,5}:      folds that contains the raw data and labels\n",
    "    '''\n",
    "    \n",
    "    f1 = []\n",
    "    f2 = []\n",
    "    f3 = []\n",
    "    f4 = []\n",
    "    f5 = []\n",
    "    \n",
    "    # Loop over each file audio\n",
    "    for num, audio in enumerate(tqdm(raw_audio)):\n",
    "        \n",
    "        if cvs[num] == 1:\n",
    "            f1.append((audio, labels[num]))\n",
    "        elif cvs[num] == 2:\n",
    "            f2.append([audio, labels[num]])\n",
    "        elif cvs[num] == 3:\n",
    "            f3.append([audio, labels[num]])\n",
    "        elif cvs[num] == 4:\n",
    "            f4.append([audio, labels[num]])\n",
    "        elif cvs[num] == 5:\n",
    "            f5.append([audio, labels[num]])\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    f1 = np.asarray(f1, dtype=object)\n",
    "    f2 = np.asarray(f2, dtype=object)\n",
    "    f3 = np.asarray(f3, dtype=object)\n",
    "    f4 = np.asarray(f4, dtype=object)\n",
    "    f5 = np.asarray(f5, dtype=object)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Folds size: %2d - %2d - %2d - %2d - %2d\" % (len(f1), len(f2), len(f3), len(f4), len(f5)))\n",
    "\n",
    "        print(\"Folds sample shape: \", len(f1[0]))\n",
    "\n",
    "        print(\"Folds sample data shape: \", f1[0][0].shape)\n",
    "        \n",
    "        print(\"Folds sample label type: \", f1[0][1].shape)\n",
    "    \n",
    "    return f1, f2, f3, f4, f5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-northeast",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "PATH = 'audio'\n",
    "raw_files, cvs, labels = Load_ESC10(PATH)\n",
    "labels = label_map(labels)\n",
    "labels = to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Split the different folds\n",
    "f1, f2, f3, f4, f5 = Split_Folds(raw_files, cvs, labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-heaven",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFNet  = load_model('MFNet10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-joint",
   "metadata": {},
   "source": [
    "## Select Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "sample = f5[10]\n",
    "\n",
    "print(\"Data shape: \", sample[0].shape)\n",
    "print(\"Label shape: \", sample[1].shape)\n",
    "\n",
    "IPython.display.Audio(sample[0], rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = np.argmax(sample[1])\n",
    "    \n",
    "# create batch of single clip\n",
    "sample = np.expand_dims(sample, axis=0)\n",
    "\n",
    "# compute segments\n",
    "segments, labels = Split_Segments(sample)\n",
    "\n",
    "# compute features\n",
    "features = Compute_MelSpec3(segments)\n",
    "\n",
    "# scale features\n",
    "features =  np.interp(features, (-100., 150.), (0, 1)).astype(np.float32)\n",
    "\n",
    "# predict all segments in the clip\n",
    "prediction = MFNet.predict(features)\n",
    "\n",
    "# convert predicted labels to class\n",
    "prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "clip_counter = 0\n",
    "for p in prediction:\n",
    "\n",
    "    if p==true_label:\n",
    "        clip_counter += 1\n",
    "\n",
    "classes = ['dog', 'rooster', 'rain', 'sea waves', 'crackling fire', 'crying baby', 'sneezing', 'clock tick', 'helicopter', 'chainsaw']\n",
    "pred_name = [classes[i] for i in prediction]\n",
    "\n",
    "print('True label: ', true_label, ' - ', classes[true_label])\n",
    "print('Predicted: ', prediction)\n",
    "\n",
    "for n in pred_name:\n",
    "    print(n)\n",
    "\n",
    "print('\\nClip Accuracy: ', clip_counter/len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-variety",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
